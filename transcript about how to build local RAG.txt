hey what's up guys Yan here and in this
video we will be building a super fast
rag application using semantic cache so
if you have not watched my previous
video about building a rag application
first you need to go there and watch
that video because we will be using the
same code base optimizing it using
semantic cache and making the results
super super
Understanding App Flow
fast let's take a detour off our
application and let's see where we can
improve our previous application as you
can see in the figure the most Rec
resource intensive steps in our
application is cross encoder reranking
and then there is the call to the large
language model which cost us both GPU
Cycles CPU cycles and if you are running
it remotely then cost as well so we want
to make sure that not all of the queries
go through these steps and how do we
determine that let's say you are running
a e-commerce store and there is a query
about the new discounts that the user
are questioning time and again so if you
are processing the same query again and
again and again then our previous
application used to go through all of
these steps again and again and again
but if we put a semantic cach in between
then what happens is that whenever a
user asks a question then we can check
if the user's question is semantically
similar to what we have stored in our
database and if the question is let's
say 80% 90% 70% similar then we can
immediately return the results back to
the user so that our application does
not have to go through these steps
saving us precious CPU Cycles GPU Cycles
Setting RAG App Repo
to get started if you have not done my
previous tutorial make sure you do it
all the code resides in this report Tre
and for this tutorial as well you are
going to need this report Tre so go to
my GitHub page and you need to copy this
and clone this on your machine to get
started so once you clone this repost
Tre what you are going to do is run mix
setup on your machine and it's going to
install all of the dependencies create
virtual environment for you and then it
just suggests you to AC the virtual
environment uh and then you'll have
something like V andv on your machine
once you're done that we are ready to go
let's also run make run to see how
RAG App Demo
application looks like so it's going to
be running in Local Host 8501 let's
click on that and this is what our
application looks like I will be
starting this tutorial from the very
start so if you have any remainers from
the previous tutorial like this database
then make sure you delete it before you
continue I just want to start with the
Clean Slate for this one and now to take
this for a spin we can again upload our
PDF file for this I'm again going to use
the AWS certified AI practitioner exam
guide I'm going to drag it put it here
process it and then I'm going to write
what is the target candidate
description ask and it's going to return
me a answer that is going to be based on
the document that I just uploaded and
it's also going to return some of the
the yeah retrieve documents and where it
fetch the answers from let's move back
to our code editor let's stop this
server for the time being for semantic
Setup: RAG App with Semantic Cache
caching we are going to need two new
libraries one is Lang chain olama with
the version 0.2.2 and then we are going
to need redish uh langin reddish in
particular which is going to be version
0.1.2 so let's install this dependencies
make sure you are installing the exact
dependency so that you do not run into
any issues when you running this on your
own machine once we have those
dependencies installed I'm going to go
to my code editor and then there are
going to be couple of new Imports that I
would like to add on my application this
includes string iio csb because we are
going to add csb documents later on and
then we are going to use olama in
bearings for our R Vector store and all
of these Reddit Vector store instance
and redis configuration instance to
configure our redis Vector store I'll
save this and for the semantic caching
you are going to be needing a radius
instant that is going to be running
external to our application in
particular inside of a Docker container
uh we are not using chroma DB which we
are already utilizing in our codebase
because in a streamlit application the
chroma DB inmemory database is
persistent within a session and it's
very difficult to work with because the
inmemory database keeps getting erased
so for the best experience we are going
to be using redish so make sure you have
Docker running on your machine or let's
say you have redish server running as a
server with a binary it does not matter
but just make sure you have redish
running if you have Docker running on
Setup: Redis with Docker
your machine you can put this command on
your command line and run Docker so it's
going to be Docker run we are going to
be running it in a detached mode and the
port it's going to expose on our local
machine is
6379 and the port it's going to attach
to inside of the Locker container is
also
6379 and we are using the official
reddish stack image and our container is
running with that in place let's
configure our redish store I'm going to
minimize the system prompt and at the
very top I'm going to add a function
Code: Configure Redis In-memory Vector Store
that's called get redish store and it's
going to return a redish vector store
instance and for embedding we are using
AMA embedding uh both of these comes
from uh langin so this is langin ama ama
embeddings and the vector reddish store
comes from langin redish and for
embedding uh we are using nomic embed
text uh the latest version because it
has a large context window and it
supports uh a variable Dimensions uh up
to 700 something uh which is pretty
great for our use case so this is the
definition of the embedding function and
once we come down we are returning a
vector store or instance of a vector
store uh we are passing the embedding
function uh that it should be using to
embed all of the queries going in and
coming out and then for the
configuration we are going to be using
the radius config class uh the index
name so this is going to be the
collection name called cast contains and
RIS URL since we are running RIS locally
um the RIS URL is followed by redis
column for/ localhost and the port is
6379 uh we can confirm this if we on
Docker PS and as you can see one of this
is the reddish stack and ports 6379 is
being forwarded to my local machine so
this is running and we can use this and
for distance metric we are using cosine
so we can use uh ukian and other
distance metric but cosine works pretty
well for this so we are using cosine and
the next is metadata scheme so metadata
scheme basically defines what type of
metadata structure we will have for our
entries in the vector database and for
this the name of the entry is going to
be or the name of the meta data is going
to be answer and its type is going to be
text so when we store data inside of
this Radice Vector store we are going to
be storing question as the key and then
answer as the metad data so that
whenever there is a santic match between
the query inside of the vector database
we are going to immediately take the
answer from the metadata and return it
to the user and that is it for our get
ready store function it basically
configures the redish store and then
returns an instance which we can use to
insert data or query it now that we have
our reddish store next we are going to
create a function that is going to store
the data inside of the reddish
store so now we have this new function
Code: Configure Cache Upload
called create cast contains and for this
we have uploaded file as the first
argument or the only argument and it's
off the type uploaded file from
streamlet so whenever we are creating
cache in our system we are going to be
using the CSV file format it's basically
going to have a pair of question and
answer so if I have to show you an
example so cash content uh based on our
current example where we are taking the
adbs certified practitioner exam guide
um let's say your application has a lot
of queries coming in
and the query most of the queries are
what is the target candidate description
and you immediately have an answer for
that and another question might be what
is AWS certified AI practitioner again
you have immediately answer for that so
it depends on what kind of system you
are building uh you may put different
columns here as well depending on your
use case but this is the most
straightforward example that I can show
you right now and this is the CSV that
we will be storing on our redish Vector
database as well whenever we upload the
CSV file in our application what we are
going to do is we are going to pass that
CSV file inside of the create cast
contents uh function and then we are
going to get value uh this basically
Returns the bytes of the file and then
we are going to decode it to utf8 which
is going to convert it into a
string and we are going to see this in
an example later on where I put a breako
and show you what the values exactly
look like and now we are going to create
a CSV reader instance so CSV reader
instance is uh an instance of a
dictionary reader and then we are
wrapping the data that we read which is
a string data inside of a string IO we
are wrapping the data inside of a string
IO because we need a fil like object
whenever we are passing a data to
dictionary reader and if we come down we
have a empty list which is called Docs
we are going to store all of our
document uh which is a lang chain
abstraction now we have our CSV reader
with all of the data that we have passed
from our CSP so basically this one when
we saw the example later on or can be
this one which is also a collection of
question answer we are just going to
ignore the instruction for the time
being so we are going to be taking each
row from the CSV file so for each row in
CSV reader and then we are going to
append to our list we are going to
append a document which is a langin
abstraction uh page content is going to
be row question so if we see row
question is going to be uh what is the
target candidate description so this is
where we are going to be using or this
is where we are going to be calculating
the semantic meaning uh that is going to
be our cache key let's say and uh after
that uh there is metadata whose key is
going to be answered and we are going to
put answer from our CSV file as a
metadata and once we have that we are
going to Loop through all of the row in
our CSV and then store it inside of the
docs and then we are going to get the
Reddit store that we just uh created and
then uh basically we are going to add
the documents all of the documents that
we have created inside of the vector
store and finally we are going to sue a
message success cach contains added now
that we have the back end for our
application ready where we can upload a
CSV file and put it into a redish in
memory Vector store we are ready to move
to the front end of the application and
for that we are going to move to the
Code: Frontend Configure Cache Document Upload
very end of our application where we
have the if name equals to main block
and this is the Side Bar of the
application where we have the document
upload area here we are going to update
this upload file variable um which is
basically stream late file uploader we
are going to support PDF as well as CSV
here
and then I'm also going to add a help
message which is going to say upload CSV
for cast results only just as a reminder
for the user they do not upload PDF or
any other file formats for the cache
obviously you can update this and
support any other file formats that you
would like but for this demo I'm just
going to support the CSV file format and
with that in place I'm also going to add
a radio button which I'm going to call
upload option and it's going to say
upload options and the options are going
to be primary or Cache if it's primary
then we are feeding the data to our
Vector database which is chroma and we
are using PDF file and if it's cache we
are using CSV and this is only for the
data that is high on demand which we can
serve immediately and also there is a
help message where uh we are saying
choose primary for uploading document
for Q&A and then we have two line braks
so that it looks visually a appealing uh
choose cache for uploading cach results
with that in place I'm going to run my
server again let's see how this looks on
the front end I'm going to go to my
browser and I'm going to refresh this
and as you can see we have this new
upload options which is primary and
cache it is primary by default um now
the drop location also shows we support
PDF and CSP but we have this help uh
tool tip as as well which says upload
CSV for cast results only and if we come
to the upload options area there is also
choose primary for uploading documents
for Q&A and right after the radio button
we are also going to check if we have
selected the correct option for primary
and the type of file we are uploading so
basically what we are saying is that if
there is uploaded file and the option is
primary and the extension of the file is
CSV then we are going to sew a error
message which is going to say CSV is
only allowed for cache option and our
program is going to exit with the error
code or the exit code one and coming
down we have this Logic on our
application where if there is a uploaded
file and if the user presses the process
button which is basically this then we
are going to pass the document and
upload it to the vector store there's
going to be a slight change so
if uh let's say upload option equals to
equals to cach
now what we are going to do is that all
splits is going to be create cast
contents and we are going to pass the
uploaded file as a parameter and else we
are going
to process a PDF and put it inside of
the chrom ADB so if we take a look
inside of it we are taking the CSV file
and then we are converting it into
document and storing it to the vector
database if I go inside of this and if I
put a breakpoint here now let's see what
Debug: Cache Upload
this looks like step by step so for this
demo I'm going to be using uh cast
contents uh for My Demo you can find
this on the report tree Linked In the
description below so my application is
running I'm going to go to my
application and then first of all I'm
going to select cach because I'm loading
the cach initially I'm going to go to my
finder I have this cached contents. CSV
here I'm going to put
it and it works just to show you that uh
there is an error message if we select
primary so if I select primary it says
CSV is only allowed for cash option so
I'm going to select cache option and I'm
going to select process and I'm going to
come back to my code editor open my
terminal my breakpoint is right here so
if I do uploaded file it's going to be a
instance of uploaded file from
streamlet and now let's see what we are
doing when we are doing uploaded file.
git value so let's start with this
uploaded file. git value we are going to
get bytes and now if we do uploaded
file. git values. decode and convert it
to
utf8 then as you can see we have this B
and then quotation mark it's going to
convert it into plain string now there
is a typo instead of decode I've return
this side so I cannot decide the
spelling so yeah basically it's
converted into a native string now as
you can see in the previous example
where we are just getting uploaded file.
G value it's getting bytes and now we
are converting that bytes into utf8
string which is this let's move on to
the next step so we have this data this
is formatted uh with n you go to the
next step so we were here I pressed n it
executed this line and now we are on
this line which is yet to be executed if
I do string io. data then it's then it
converts it into a string object and
let's go inside our docs is empty and we
are going to go inside of the for Loop
and we are at this line docs. append so
we are going to take a look at the row
so it's going to be in a dictionary
format so if I take a look at the row we
have the key question and then we have
the key answer but which is definitely
very hard to see okay here is the answer
but you can also do row. keys to see
that there are question and answer in
this row and we are basically taking
that and putting it inside of the
docs so if we do this uh docs to depend
and if we check the docs there is
already a document which is the first
line of our CSV file uh which is what is
the target candidate
description uh I'll just press C
continue to carry on what whatever it
wants to do so it will not consider
stopping anywhere else unless there is a
breakpoint so I'll just do c my
application is running and as you can
see cast contents has been added so our
cast is loaded into inmemory database
redish now let's see how our cache looks
like for that I'm going to open a new
terminal instance and if I do Docker PS
the name of my container is STO T so
what I'm going to do is Docker exec uh
minus it which means I'm going to attach
a interactive TTY or terminal inside of
the container named stoic davan and I'm
going to attach a bash terminal with
that in place I'm going to write redis
minus CLI to go inside the red database
and then I'm going to write all caps is
aster and as you can see we have two
cast contents one for each row on our
CSV file but if we use any visual tool
like medis which I'm using in this case
so if I refresh this I can see two cast
contents and if I look at it properly I
can see that the text is what is a
certified eii practitioner and the
answer is basically here so now our
cache is loaded and it's ready to fire
up but before that uh we do not have
anything to query the cache we just have
Code: Configure Query Cache
a function uh which creates a a cache
content and we just created a function
uh which Returns the redish Cash Store
so next we are going to create a
function which is going to query the
redish cache and return us the results
if there is a match up to a certain
threshold in the semantic meaning here
we are going to write our function which
is going to be called query semantic
cache and it's going to take a argument
of query which is whatever the user
Types on our UI number of results for
this I'm just going to put it as one uh
because whenever we are equating the
vector database it usually Returns the
most relevant result as the top result
so we will not need more than one
because we are going to take the first
result the top result and we are going
to check how much similar it is with
this threshold and for this we have this
threshold argument of type float and for
this demo we are going to use 80
percentage as the threshold meaning
whatever query we are running and
whatever key that is stored on the
vector database the semantic meaning
should be 80% similar on the next line
we are getting the vector store and then
uh we are quing the vector store with
similarity search with score so this is
going to return a cosine similarity
score uh because if you go to the get
ready store we have the distance metric
as cosine so whenever we are running
this function it is going to return
cosine similarity and then we are going
to pass the query and the number of
return results is going to be one
and sometimes if it does not return any
results because there is no similar data
then it's basically going to return none
and then here is the interesting part
where the threshold comes into the
picture so what we are doing is that it
returns a cosine similarity and we are
converting that cosine similarity into a
cosine distance and for that we are
going to take one and subtract it with
the absolute value of the cosine
similarity that the results return and
as you can see we are taking the first
value uh because it returns only one
value but it's a nested list so we need
to take the first item uh from that list
and then we are going to take the second
item which is going to be the cosine
similarity from it and then we are going
to multiply it by 100 so that we get a
percentage and then uh percentage is
basically a pretty weird name I think I
should name it as Ma match percentage
maybe yeah this sounds more like it so
if the match percentage is greater than
or equal to 80% then we are happy with
our results and if there is a match we
are going to return the results and if
it does not match the threshold we are
basically going to return none and if we
come down to the main application block
here uh will'll tog all the sidebar and
now we are just left with this section
so before we go to query collection
which is going to hit our Vector
database and then it's going to perform
cross encoder reranking and all of these
Jazz we are going to put cast results
here so cast results is going to be
query semantic cache and then the query
is going to be our prompt once we do
that we also need to check if there is
cach results or not so if there is cach
results we are just going to do st. WR
and then cash results we are going to
take the first item in the cash results
because we are just returning one item
from the vector database and then we are
going to the Jero item which is going to
be the document object and then we are
going to say metadata is where our
answer is so we are going to take answer
here and if there is no cache results
then we are going to perform all of
these Jazz so we are just going to put
this inside of a else
block now let's see this in action let's
see like um how this semantic query
works so first of all we are going to
ask the question that is going to be
like 99% match because I'm going to ask
the same question that we feed it to the
Debug/Demo: Semantic Cache
uh Vector database but I'm also going to
put breakpoint here let's see if I have
other break points yeah I'm going to
remove this breako it's no longer needed
I have this one break
point which is when I'm creating the
semantic cache so so let's go to our
application and then I'm going to paste
what is the target candidate uh
description then I'm going to ask the
question and then if we go back to our
terminal we will be stopped here in the
results so if I look at results and L of
results it's going to be one so we are
just returning one because our end
results is one and as you can see it is
returning this data as a list so we need
to get the Z index
item which will return this uh Tuple
again and then we need to take the zero
index item of this pupil which is
finally the document object but as we
can already see there is a metadata
field the second item here is the score
that we are looking for which is the
cosine similarity score so if I do
absolute 0 0 I'm going to get a document
where I can do document if I go down
uh if I'm I can do like dot metadata it
gives me a metadata which is a
dictionary and get answer from here but
if I want to get a result which is the
cosine similarity then I have to use the
or the second item which is going to be
this value so let's go to the very top
and now we are uh using the match
percentage so if I do next and match
percentage and if I check match
percentage you can see it's 99.
99994 which basically means it's pretty
similar and if I do see it's going to
immediately return the answer to my
system and as you can see uh we are
seeing this weird characters line Break
characters uh backward SL minus n this
is because uh let's see if we are asking
the question and if we see the results
you can notice there are double backs
slash followed by n the line break
character so if you have double n it
basically skips the line break character
uh which results in this line break
character not being rendered to our
screen so to fix that what we are going
to do is come uh very down and wherever
we are fetching the answer we are going
to do replace followed by this I need to
delete this put it here and then it
works so I'm I'm removing or I'm
replacing double sln with a single line
break character so that it renders the
line break properly I'm going to run it
again so if I come down here it's
nothing's going to change I'm just going
to remove the de debugger now so if I
come to my application again and if I
ask the question as you can see it's
well formatted and it gives me the
answer within milliseconds um I can try
another what type of person can give the
exam and I can ask it so you can also
set the threshold to you know maybe 70
if it makes sense for you I'm going to
see the results again and then it's just
giving the exam overview for the most
part and then um I'm going to do next
I'm going to check the match percentage
it's just 54 for this time uh so it's
going to go through the large language
model cross encoders re ranking and all
of that so there are also different ways
of questioning uh the model uh what is
AWS certified AI practitioner so instead
of that I can just ask tell me about AWS
certified AI practitioner so it's going
to get the results and then uh as you
can see it has a cash hit but we need to
check the threshold so if I go here and
if I check the match percentage it's 96
not 99 but it's going to return the
result immediately so if I do see as you
can see all of these are cast results
that is being returned
immediately so you can play around with
this for a bit and figure out what works
best for you and what is the best
strategy moving forward also in the
Bonus: Scripts (Token Count & CSV generator)
codebase you can find some handy scripts
uh which is inside of the scripts if you
are feeding in a large amount of data
inside of the vector database then you
need to take the amount of token into
consideration so this so this function
or this model basically helps you to
identify if you are passing the correct
number of tokens inside of the embedding
function and if not then you can like
trim your answer or make it however you
want and if you want to see how I made
the CSV file uh first of all uh what I
did is that I take all of the questions
uh for this example I'm just taking two
questions which is very high in demand
let's say a lot of people are trying to
know about the AI exam from AWS and they
are constantly asking question about
that to our system then we decide to
cach it so basically this is the
question and this is the answer also
notice that this is a raw string so that
it does not render this line Break
characters and yeah the name of the file
is Gast contains and you also have this
mini movie CSV which I got from hugging
face there were like 30,000 40,000 data
inside of this CSV but I cleaned it up
and I think there are only 500 data for
the time being yeah so you can use this